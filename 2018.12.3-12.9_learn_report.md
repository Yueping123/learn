```
1、启用bert-serving，调用bert的BERT-Base, Uncased: 12-layer, 768-hidden, 12-heads, 110M parameters里面的bert_model.ckpt ：vocab.txt，bert_config.json) 

(py36) yueping@gpu12:~/bert$ bert-serving-start  -model_dir ./uncased_L-12_H-768_A-12/  -max_batch_size=64 -num_worker=1
usage: /home/yueping/anaconda3/envs/py36/bin/bert-serving-start -model_dir ./uncased_L-12_H-768_A-12/ -max_batch_size=64 -num_worker=1
                 ARG   VALUE
__________________________________________________
 gpu_memory_fraction = 0.5
      max_batch_size = 64
         max_seq_len = 25
           model_dir = ./uncased_L-12_H-768_A-12/
          num_worker = 1
       pooling_layer = [-2]
    pooling_strategy = REDUCE_MEAN
                port = 5555
            port_out = 5556

WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpdkbd3irt
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fbcef594b70>) includes params argument, but params are not passed to Estimator.
2018-12-09 21:53:49.730837: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-12-09 21:53:51.642548: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:02:00.0
totalMemory: 10.91GiB freeMemory: 10.75GiB
2018-12-09 21:53:51.642613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2018-12-09 21:53:52.178650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-12-09 21:53:52.178724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2018-12-09 21:53:52.178737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2018-12-09 21:53:52.179209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5585 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)
I:WORKER-0:[__i:gen:300]:ready and listening!

2、将自己的训练集使用bert的预训练模型生成词向量。

from bert_serving.client import BertClient
    bc = BertClient()
    my_sentences = [s for s in sent_list]
# doing encoding in one-shot
    vec = bc.encode(my_sentences)
    print(vec)
  
  3、将生成的词向量带入biLSTM模型中运行得到如下结果：
  
  [1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1 1 1
 1 1 1 1 1 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1
 1 0 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0
 1 1 1 1 1 0 1 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 1 0 1 1 1 1 1
 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1
 1 0 1 1 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 1 0
 1 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0
 1 0 1 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 0 1 1
 1 1 0 0 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1
 1 1 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0 1 0 1 1 1 0 1
 0 1 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0
 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1]
  
  4、下周工作：生成的预测标签转换为list，在提交到codelab，采用BERT-Large, Uncased：24层，1024个隐藏，16个头，340M参数微调bert参数。
```
