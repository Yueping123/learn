#### 1、统计每个sentence的单词数量并画出分布图（使用的脚本为im1.py),设置的maxlen=80
![image](https://github.com/Yueping123/learn/blob/master/task9_A_%E5%8D%95%E8%AF%8D%E5%88%86%E5%B8%83%E5%9B%BE.png)

#### 2、使用cnn模型运行的log

'''
_______________________________________________
2018-11-11 13:48:21,241: INFO: running C:/Users/YP/Desktop/pro/imdb_cnn_A.py
2018-11-11 13:48:21,241: INFO: loading data...
2018-11-11 13:48:21,288: INFO: data loaded!
2018-11-11 13:48:21,397: INFO: n_train_sample [n_train_sample]: 6454
2018-11-11 13:48:21,397: INFO: n_test_sample [n_test_sample]: 592
2018-11-11 13:48:21,397: INFO: len_sentence [len_sentence]: 489
2018-11-11 13:48:21,397: INFO: num of word vector [max_features]: 7976
2018-11-11 13:48:21,397: INFO: dimension of word vector [num_features]: 300
2018-11-11 13:48:21.429392: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
WARNING:tensorflow:From C:\Users\YP\Desktop\pro\venv\lib\site-packages\tensorflow\python\util\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.
Instructions for updating:
`NHWC` for data_format is deprecated, use `NWC` instead
2018-11-11 13:48:21,647: WARNING: From C:\Users\YP\Desktop\pro\venv\lib\site-packages\tensorflow\python\util\deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.
Instructions for updating:
`NHWC` for data_format is deprecated, use `NWC` instead
Train on 6454 samples, validate on 1599 samples
Epoch 1/10
 - 27s - loss: 0.5460 - acc: 0.7510 - val_loss: 0.4767 - val_acc: 0.7580
Epoch 2/10
 - 28s - loss: 0.4345 - acc: 0.7896 - val_loss: 0.4050 - val_acc: 0.8193
Epoch 3/10
 - 29s - loss: 0.3782 - acc: 0.8322 - val_loss: 0.3975 - val_acc: 0.8236
Epoch 4/10
 - 29s - loss: 0.3230 - acc: 0.8567 - val_loss: 0.3855 - val_acc: 0.8380
Epoch 5/10
 - 31s - loss: 0.2690 - acc: 0.8874 - val_loss: 0.3879 - val_acc: 0.8455
Epoch 6/10
 - 32s - loss: 0.2224 - acc: 0.9072 - val_loss: 0.4036 - val_acc: 0.8311
Epoch 7/10
 - 27s - loss: 0.1759 - acc: 0.9314 - val_loss: 0.4127 - val_acc: 0.8537
Epoch 8/10
 - 27s - loss: 0.1536 - acc: 0.9439 - val_loss: 0.4552 - val_acc: 0.8487
Epoch 9/10
 - 27s - loss: 0.1267 - acc: 0.9517 - val_loss: 0.4874 - val_acc: 0.8243
Epoch 10/10
 - 29s - loss: 0.1157 - acc: 0.9589 - val_loss: 0.4850 - val_acc: 0.8449
_________________________________________________________________
model.summary()
_
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 489)               0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 489, 300)          2392800   
_________________________________________________________________
dropout_1 (Dropout)          (None, 489, 300)          0         
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 487, 60)           54060     
_________________________________________________________________
max_pooling1d_1 (MaxPooling1 (None, 243, 60)           0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 14580)             0         
_________________________________________________________________
dense_1 (Dense)              (None, 70)                1020670   
_________________________________________________________________
dropout_2 (Dropout)          (None, 70)                0         
_________________________________________________________________
activation_1 (Activation)    (None, 70)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 142       
=================================================================
Total params: 3,467,672
Trainable params: 1,074,872
Non-trainable params: 2,392,800
_________________________________________________________________
Traceback (most recent call last):

输出的test.csv的label值：
[0 0 0 0 0 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0
 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 0 1
 0 1 1 1 0 0 1 0 1 1 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0
 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0
 0 1 0 1 1 1 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0
 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 0
 0 0 1 0 0 0 0 0 1 1 1 0 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 0 0 0 1 0 1 0
 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 0 0
 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 1 1 0 0 0 1 1 1 1 1
 1 0 0 1 1 1 1 1 0 0 1 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0
 1 0 1 1 0 0 0 0 0 0 0 1 1 1 1 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 1 0 0 0
 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0
 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 1 0
 0 0 1 1 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 0 1
 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0
 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1]
 
####  3、使用bilstm运行的log（2个epoch）

2018-11-10 21:07:50,824: INFO: n_train_sample [n_train_sample]: 6454
2018-11-10 21:07:50,824: INFO: n_test_sample [n_test_sample]: 592
2018-11-10 21:07:50,824: INFO: len_sentence [len_sentence]: 489
2018-11-10 21:07:50,824: INFO: num of word vector [max_features]: 7976
2018-11-10 21:07:50,824: INFO: dimension of word vector [num_features]: 300
2018-11-10 21:07:50.839131: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
_________________________________________________________________
##### Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 489)               0         
_________________________________________________________________
embedding_1 (Embedding)      (None, 489, 300)          2392800   
_________________________________________________________________
bidirectional_1 (Bidirection (None, 200)               320800    
_________________________________________________________________
dense_1 (Dense)              (None, 100)               20100     
_________________________________________________________________
##### dense_2 (Dense)              (None, 2)                 202       
=================================================================
Total params: 2,733,902
Trainable params: 341,102
Non-trainable params: 2,392,800
_________________________________________________________________

C:/Users/YP/Desktop/pro/bilstm_A.py:143: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.
  model.fit(X_train, y_train, validation_data=(X_dev, y_dev),nb_epoch=10, batch_size=50)
Train on 6454 samples, validate on 1599 samples
Epoch 1/10

  50/6454 [..............................] - ETA: 12:29 - loss: 0.6710 - acc: 0.6200

100/6454 [..............................] - ETA: 11:35 - loss: 0.7678 - acc: 0.6500

150/6454 [..............................] - ETA: 11:37 - loss: 0.6368 - acc: 0.7667

200/6454 [..............................] - ETA: 11:27 - loss: 0.5454 - acc: 0.7800

250/6454 [>.............................] - ETA: 11:31 - loss: 0.4702 - acc: 0.8120

300/6454 [>.............................] - ETA: 11:31 - loss: 0.4195 - acc: 0.8267

350/6454 [>.............................] - ETA: 11:30 - loss: 0.3781 - acc: 0.8514 
400/6454 [>.............................] - ETA: 11:21 - loss: 0.3411 - acc: 0.8700

450/6454 [=>............................] - ETA: 11:17 - loss: 0.3107 - acc: 0.8844

500/6454 [=>............................] - ETA: 11:13 - loss: 0.2835 - acc: 0.8960

550/6454 [=>............................] - ETA: 11:08 - loss: 0.2616 - acc: 0.9055

600/6454 [=>............................] - ETA: 11:00 - loss: 0.2421 - acc: 0.9133

650/6454 [==>...........................] - ETA: 10:55 - loss: 0.2248 - acc: 0.9200

700/6454 [==>...........................] - ETA: 10:53 - loss: 0.2096 - acc: 0.9257

750/6454 [==>...........................] - ETA: 10:48 - loss: 0.1964 - acc: 0.9307

800/6454 [==>...........................] - ETA: 10:46 - loss: 0.1851 - acc: 0.9350

850/6454 [==>...........................] - ETA: 10:40 - loss: 0.1748 - acc: 0.9388

900/6454 [===>..........................] - ETA: 10:32 - loss: 0.1656 - acc: 0.9422

950/6454 [===>..........................] - ETA: 10:25 - loss: 0.1572 - acc: 0.9453

1000/6454 [===>..........................] - ETA: 10:21 - loss: 0.1497 - acc: 0.9480

1050/6454 [===>..........................] - ETA: 10:17 - loss: 0.1428 - acc: 0.9505

1100/6454 [====>.........................] - ETA: 10:10 - loss: 0.1366 - acc: 0.9527

1150/6454 [====>.........................] - ETA: 10:04 - loss: 0.1308 - acc: 0.9548

1200/6454 [====>.........................] - ETA: 9:58 - loss: 0.1255 - acc: 0.9567 


1250/6454 [====>.........................] - ETA: 9:52 - loss: 0.1207 - acc: 0.9584

1300/6454 [=====>........................] - ETA: 9:48 - loss: 0.1161 - acc: 0.9600

1350/6454 [=====>........................] - ETA: 9:42 - loss: 0.1120 - acc: 0.9615

1400/6454 [=====>........................] - ETA: 9:37 - loss: 0.1080 - acc: 0.9629

1450/6454 [=====>........................] - ETA: 9:33 - loss: 0.1044 - acc: 0.9641

1500/6454 [=====>........................] - ETA: 9:30 - loss: 0.1010 - acc: 0.9653

1550/6454 [======>.......................] - ETA: 9:24 - loss: 0.0978 - acc: 0.9665

1600/6454 [======>.......................] - ETA: 9:19 - loss: 0.0948 - acc: 0.9675

1650/6454 [======>.......................] - ETA: 9:14 - loss: 0.0920 - acc: 0.9685

1700/6454 [======>.......................] - ETA: 9:09 - loss: 0.0893 - acc: 0.9694

1750/6454 [=======>......................] - ETA: 9:03 - loss: 0.0868 - acc: 0.9703
1800/6454 [=======>......................] - ETA: 8:58 - loss: 0.0844 - acc: 0.9711
1850/6454 [=======>......................] - ETA: 8:53 - loss: 0.0821 - acc: 0.9719
1900/6454 [=======>......................] - ETA: 8:48 - loss: 0.0800 - acc: 0.9726
1950/6454 [========>.....................] - ETA: 8:43 - loss: 0.0780 - acc: 0.9733
2000/6454 [========>.....................] - ETA: 8:37 - loss: 0.0761 - acc: 0.9740
2050/6454 [========>.....................] - ETA: 8:31 - loss: 0.0742 - acc: 0.9746
2100/6454 [========>.....................] - ETA: 8:26 - loss: 0.0725 - acc: 0.9752
2150/6454 [========>.....................] - ETA: 8:21 - loss: 0.0708 - acc: 0.9758
2200/6454 [=========>....................] - ETA: 8:17 - loss: 0.0692 - acc: 0.9764
2250/6454 [=========>....................] - ETA: 8:14 - loss: 0.0677 - acc: 0.9769
2300/6454 [=========>....................] - ETA: 8:08 - loss: 0.0662 - acc: 0.9774
2350/6454 [=========>....................] - ETA: 8:03 - loss: 0.0648 - acc: 0.9779
2400/6454 [==========>...................] - ETA: 7:57 - loss: 0.0635 - acc: 0.9783
2450/6454 [==========>...................] - ETA: 7:51 - loss: 0.0622 - acc: 0.9788
2500/6454 [==========>...................] - ETA: 7:48 - loss: 0.0610 - acc: 0.9792
2550/6454 [==========>...................] - ETA: 7:43 - loss: 0.0598 - acc: 0.9796
2600/6454 [===========>..................] - ETA: 7:39 - loss: 0.0586 - acc: 0.9800
2650/6454 [===========>..................] - ETA: 7:34 - loss: 0.0575 - acc: 0.9804
2700/6454 [===========>..................] - ETA: 7:27 - loss: 0.0565 - acc: 0.9807
2750/6454 [===========>..................] - ETA: 7:21 - loss: 0.0554 - acc: 0.9811
2800/6454 [============>.................] - ETA: 7:15 - loss: 0.0545 - acc: 0.9814
2850/6454 [============>.................] - ETA: 7:09 - loss: 0.0535 - acc: 0.9818
2900/6454 [============>.................] - ETA: 7:03 - loss: 0.0526 - acc: 0.9821
2950/6454 [============>.................] - ETA: 6:58 - loss: 0.0517 - acc: 0.9824
3000/6454 [============>.................] - ETA: 6:52 - loss: 0.0508 - acc: 0.9827
3050/6454 [=============>................] - ETA: 6:46 - loss: 0.0500 - acc: 0.9830
3100/6454 [=============>................] - ETA: 6:40 - loss: 0.0492 - acc: 0.9832
3150/6454 [=============>................] - ETA: 6:34 - loss: 0.0484 - acc: 0.9835
3200/6454 [=============>................] - ETA: 6:28 - loss: 0.0477 - acc: 0.9837
3250/6454 [==============>...............] - ETA: 6:22 - loss: 0.0469 - acc: 0.9840
3300/6454 [==============>...............] - ETA: 6:17 - loss: 0.0462 - acc: 0.9842
3350/6454 [==============>...............] - ETA: 6:10 - loss: 0.0456 - acc: 0.9845
3400/6454 [==============>...............] - ETA: 6:05 - loss: 0.0449 - acc: 0.9847
3450/6454 [===============>..............] - ETA: 5:59 - loss: 0.0442 - acc: 0.9849
3500/6454 [===============>..............] - ETA: 5:53 - loss: 0.0436 - acc: 0.9851
3550/6454 [===============>..............] - ETA: 5:47 - loss: 0.0430 - acc: 0.9854
3600/6454 [===============>..............] - ETA: 5:41 - loss: 0.0424 - acc: 0.9856
3650/6454 [===============>..............] - ETA: 5:35 - loss: 0.0418 - acc: 0.9858
3700/6454 [================>.............] - ETA: 5:29 - loss: 0.0413 - acc: 0.9859
3750/6454 [================>.............] - ETA: 5:23 - loss: 0.0407 - acc: 0.9861
3800/6454 [================>.............] - ETA: 5:16 - loss: 0.0402 - acc: 0.9863
3850/6454 [================>.............] - ETA: 5:10 - loss: 0.0397 - acc: 0.9865
3900/6454 [=================>............] - ETA: 5:04 - loss: 0.0391 - acc: 0.9867
3950/6454 [=================>............] - ETA: 4:58 - loss: 0.0387 - acc: 0.9868
4000/6454 [=================>............] - ETA: 4:52 - loss: 0.0382 - acc: 0.9870
4050/6454 [=================>............] - ETA: 4:46 - loss: 0.0377 - acc: 0.9872
4100/6454 [==================>...........] - ETA: 4:40 - loss: 0.0372 - acc: 0.9873
4150/6454 [==================>...........] - ETA: 4:34 - loss: 0.0368 - acc: 0.9875
4200/6454 [==================>...........] - ETA: 4:28 - loss: 0.0364 - acc: 0.9876
4250/6454 [==================>...........] - ETA: 4:22 - loss: 0.0359 - acc: 0.9878
4300/6454 [==================>...........] - ETA: 4:16 - loss: 0.0355 - acc: 0.9879
4350/6454 [===================>..........] - ETA: 4:10 - loss: 0.0351 - acc: 0.9880
4400/6454 [===================>..........] - ETA: 4:05 - loss: 0.0347 - acc: 0.9882
4450/6454 [===================>..........] - ETA: 3:59 - loss: 0.0343 - acc: 0.9883
4500/6454 [===================>..........] - ETA: 3:54 - loss: 0.0339 - acc: 0.9884
4550/6454 [====================>.........] - ETA: 3:48 - loss: 0.0336 - acc: 0.9886
4600/6454 [====================>.........] - ETA: 3:42 - loss: 0.0332 - acc: 0.9887
4650/6454 [====================>.........] - ETA: 3:36 - loss: 0.0328 - acc: 0.9888
4700/6454 [====================>.........] - ETA: 3:30 - loss: 0.0325 - acc: 0.9889
4750/6454 [=====================>........] - ETA: 3:24 - loss: 0.0321 - acc: 0.9891
4800/6454 [=====================>........] - ETA: 3:18 - loss: 0.0318 - acc: 0.9892
4850/6454 [=====================>........] - ETA: 3:12 - loss: 0.0315 - acc: 0.9893
4900/6454 [=====================>........] - ETA: 3:07 - loss: 0.0312 - acc: 0.9894
4950/6454 [======================>.......] - ETA: 3:01 - loss: 0.0309 - acc: 0.9895
5000/6454 [======================>.......] - ETA: 2:54 - loss: 0.0305 - acc: 0.9896
5050/6454 [======================>.......] - ETA: 2:48 - loss: 0.0302 - acc: 0.9897
5100/6454 [======================>.......] - ETA: 2:42 - loss: 0.0299 - acc: 0.9898
5150/6454 [======================>.......] - ETA: 2:36 - loss: 0.0297 - acc: 0.9899
5200/6454 [=======================>......] - ETA: 2:30 - loss: 0.0294 - acc: 0.9900
5250/6454 [=======================>......] - ETA: 2:24 - loss: 0.0291 - acc: 0.9901
5300/6454 [=======================>......] - ETA: 2:18 - loss: 0.0288 - acc: 0.9902
5350/6454 [=======================>......] - ETA: 2:12 - loss: 0.0285 - acc: 0.9903
5400/6454 [========================>.....] - ETA: 2:06 - loss: 0.0283 - acc: 0.9904
5450/6454 [========================>.....] - ETA: 2:00 - loss: 0.0280 - acc: 0.9905
5500/6454 [========================>.....] - ETA: 1:54 - loss: 0.0278 - acc: 0.9905
5550/6454 [========================>.....] - ETA: 1:48 - loss: 0.0275 - acc: 0.9906
5600/6454 [=========================>....] - ETA: 1:42 - loss: 0.0273 - acc: 0.9907
5650/6454 [=========================>....] - ETA: 1:36 - loss: 0.0270 - acc: 0.9908
5700/6454 [=========================>....] - ETA: 1:30 - loss: 0.0268 - acc: 0.9909
5750/6454 [=========================>....] - ETA: 1:24 - loss: 0.0266 - acc: 0.9910
5800/6454 [=========================>....] - ETA: 1:18 - loss: 0.0263 - acc: 0.9910
5850/6454 [==========================>...] - ETA: 1:12 - loss: 0.0261 - acc: 0.9911
5900/6454 [==========================>...] - ETA: 1:06 - loss: 0.0259 - acc: 0.9912
5950/6454 [==========================>...] - ETA: 1:00 - loss: 0.0257 - acc: 0.9913
6000/6454 [==========================>...] - ETA: 54s - loss: 0.0255 - acc: 0.9913 
6050/6454 [===========================>..] - ETA: 48s - loss: 0.0252 - acc: 0.9914
6100/6454 [===========================>..] - ETA: 42s - loss: 0.0250 - acc: 0.9915
6150/6454 [===========================>..] - ETA: 36s - loss: 0.0248 - acc: 0.9915
6200/6454 [===========================>..] - ETA: 30s - loss: 0.0246 - acc: 0.9916
6250/6454 [============================>.] - ETA: 24s - loss: 0.0244 - acc: 0.9917
6300/6454 [============================>.] - ETA: 18s - loss: 0.0242 - acc: 0.9917
6350/6454 [============================>.] - ETA: 12s - loss: 0.0241 - acc: 0.9918
6400/6454 [============================>.] - ETA: 6s - loss: 0.0239 - acc: 0.9919 
6450/6454 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9919
6454/6454 [==============================] - 790s 122ms/step - loss: 0.0237 - acc: 0.9919 - val_loss: 3.7044e-06 - val_acc: 1.0000

Epoch 10/10

  50/6454 [..............................] - ETA: 26:19 - loss: 1.1921e-07 - acc: 1.0000
 100/6454 [..............................] - ETA: 26:42 - loss: 1.1981e-07 - acc: 1.0000
 150/6454 [..............................] - ETA: 25:50 - loss: 1.1961e-07 - acc: 1.0000
 200/6454 [..............................] - ETA: 25:54 - loss: 1.2010e-07 - acc: 1.0000
 250/6454 [>.............................] - ETA: 25:33 - loss: 1.1992e-07 - acc: 1.0000
 300/6454 [>.............................] - ETA: 24:55 - loss: 1.1981e-07 - acc: 1.0000
 350/6454 [>.............................] - ETA: 25:01 - loss: 1.1972e-07 - acc: 1.0000
 400/6454 [>.............................] - ETA: 24:44 - loss: 1.1966e-07 - acc: 1.0000
 450/6454 [=>............................] - ETA: 24:37 - loss: 1.1961e-07 - acc: 1.0000
 500/6454 [=>............................] - ETA: 24:43 - loss: 1.1957e-07 - acc: 1.0000
 550/6454 [=>............................] - ETA: 24:17 - loss: 1.1953e-07 - acc: 1.0000
 600/6454 [=>............................] - ETA: 24:06 - loss: 1.1951e-07 - acc: 1.0000
 650/6454 [==>...........................] - ETA: 23:55 - loss: 1.1948e-07 - acc: 1.0000
 700/6454 [==>...........................] - ETA: 23:42 - loss: 1.1946e-07 - acc: 1.0000
 750/6454 [==>...........................] - ETA: 23:32 - loss: 1.1945e-07 - acc: 1.0000
 800/6454 [==>...........................] - ETA: 23:16 - loss: 1.1943e-07 - acc: 1.0000
 850/6454 [==>...........................] - ETA: 23:01 - loss: 1.1942e-07 - acc: 1.0000
 900/6454 [===>..........................] - ETA: 22:46 - loss: 1.1941e-07 - acc: 1.0000
 950/6454 [===>..........................] - ETA: 22:37 - loss: 1.1940e-07 - acc: 1.0000
1000/6454 [===>..........................] - ETA: 22:22 - loss: 1.1939e-07 - acc: 1.0000
1050/6454 [===>..........................] - ETA: 22:11 - loss: 1.1938e-07 - acc: 1.0000
1100/6454 [====>.........................] - ETA: 21:56 - loss: 1.1937e-07 - acc: 1.0000
1150/6454 [====>.........................] - ETA: 21:48 - loss: 1.1936e-07 - acc: 1.0000
1200/6454 [====>.........................] - ETA: 21:34 - loss: 1.1936e-07 - acc: 1.0000
1250/6454 [====>.........................] - ETA: 21:19 - loss: 1.1935e-07 - acc: 1.0000
1300/6454 [=====>........................] - ETA: 21:07 - loss: 1.1935e-07 - acc: 1.0000
1350/6454 [=====>........................] - ETA: 20:50 - loss: 1.1934e-07 - acc: 1.0000
1400/6454 [=====>........................] - ETA: 20:36 - loss: 1.1934e-07 - acc: 1.0000
1450/6454 [=====>........................] - ETA: 20:24 - loss: 1.1933e-07 - acc: 1.0000
1500/6454 [=====>........................] - ETA: 20:12 - loss: 1.1933e-07 - acc: 1.0000
1550/6454 [======>.......................] - ETA: 19:58 - loss: 1.1932e-07 - acc: 1.0000
1600/6454 [======>.......................] - ETA: 19:47 - loss: 1.1932e-07 - acc: 1.0000
1650/6454 [======>.......................] - ETA: 19:33 - loss: 1.1932e-07 - acc: 1.0000
1700/6454 [======>.......................] - ETA: 19:22 - loss: 1.1931e-07 - acc: 1.0000
1750/6454 [=======>......................] - ETA: 19:08 - loss: 1.1931e-07 - acc: 1.0000
1800/6454 [=======>......................] - ETA: 18:54 - loss: 1.1931e-07 - acc: 1.0000
1850/6454 [=======>......................] - ETA: 18:39 - loss: 1.1931e-07 - acc: 1.0000
1900/6454 [=======>......................] - ETA: 18:24 - loss: 1.1930e-07 - acc: 1.0000
1950/6454 [========>.....................] - ETA: 18:14 - loss: 1.1930e-07 - acc: 1.0000
2000/6454 [========>.....................] - ETA: 18:02 - loss: 1.1930e-07 - acc: 1.0000
2050/6454 [========>.....................] - ETA: 17:49 - loss: 1.1930e-07 - acc: 1.0000
2100/6454 [========>.....................] - ETA: 17:38 - loss: 1.1929e-07 - acc: 1.0000
2150/6454 [========>.....................] - ETA: 17:24 - loss: 1.1929e-07 - acc: 1.0000
2200/6454 [=========>....................] - ETA: 17:12 - loss: 1.1929e-07 - acc: 1.0000
2250/6454 [=========>....................] - ETA: 16:59 - loss: 1.1929e-07 - acc: 1.0000
2300/6454 [=========>....................] - ETA: 16:46 - loss: 1.1929e-07 - acc: 1.0000
2350/6454 [=========>....................] - ETA: 16:32 - loss: 1.1929e-07 - acc: 1.0000
2400/6454 [==========>...................] - ETA: 16:21 - loss: 1.1928e-07 - acc: 1.0000
2450/6454 [==========>...................] - ETA: 16:09 - loss: 1.1928e-07 - acc: 1.0000
2500/6454 [==========>...................] - ETA: 15:58 - loss: 1.1928e-07 - acc: 1.0000
2550/6454 [==========>...................] - ETA: 15:47 - loss: 1.1928e-07 - acc: 1.0000
2600/6454 [===========>..................] - ETA: 15:37 - loss: 1.1928e-07 - acc: 1.0000
2650/6454 [===========>..................] - ETA: 15:25 - loss: 1.1928e-07 - acc: 1.0000
2700/6454 [===========>..................] - ETA: 15:14 - loss: 1.1928e-07 - acc: 1.0000
2750/6454 [===========>..................] - ETA: 15:01 - loss: 1.1927e-07 - acc: 1.0000
2800/6454 [============>.................] - ETA: 14:50 - loss: 1.1927e-07 - acc: 1.0000
2850/6454 [============>.................] - ETA: 14:38 - loss: 1.1927e-07 - acc: 1.0000
2900/6454 [============>.................] - ETA: 14:26 - loss: 1.1927e-07 - acc: 1.0000
2950/6454 [============>.................] - ETA: 14:13 - loss: 1.1927e-07 - acc: 1.0000
3000/6454 [============>.................] - ETA: 14:01 - loss: 1.1927e-07 - acc: 1.0000
3050/6454 [=============>................] - ETA: 13:49 - loss: 1.1927e-07 - acc: 1.0000
3100/6454 [=============>................] - ETA: 13:38 - loss: 1.1927e-07 - acc: 1.0000
3150/6454 [=============>................] - ETA: 13:27 - loss: 1.1927e-07 - acc: 1.0000
3200/6454 [=============>................] - ETA: 13:16 - loss: 1.1927e-07 - acc: 1.0000
3250/6454 [==============>...............] - ETA: 13:03 - loss: 1.1926e-07 - acc: 1.0000
3300/6454 [==============>...............] - ETA: 12:52 - loss: 1.1926e-07 - acc: 1.0000
3350/6454 [==============>...............] - ETA: 12:41 - loss: 1.1926e-07 - acc: 1.0000
3400/6454 [==============>...............] - ETA: 12:28 - loss: 1.1926e-07 - acc: 1.0000
3450/6454 [===============>..............] - ETA: 12:16 - loss: 1.1926e-07 - acc: 1.0000
3500/6454 [===============>..............] - ETA: 12:03 - loss: 1.1926e-07 - acc: 1.0000
3550/6454 [===============>..............] - ETA: 11:51 - loss: 1.1926e-07 - acc: 1.0000
3600/6454 [===============>..............] - ETA: 11:38 - loss: 1.1926e-07 - acc: 1.0000
3650/6454 [===============>..............] - ETA: 11:26 - loss: 1.1926e-07 - acc: 1.0000
3700/6454 [================>.............] - ETA: 11:13 - loss: 1.1926e-07 - acc: 1.0000
3750/6454 [================>.............] - ETA: 11:00 - loss: 1.1926e-07 - acc: 1.0000
3800/6454 [================>.............] - ETA: 10:49 - loss: 1.1926e-07 - acc: 1.0000
3850/6454 [================>.............] - ETA: 10:36 - loss: 1.1926e-07 - acc: 1.0000
3900/6454 [=================>............] - ETA: 10:23 - loss: 1.1926e-07 - acc: 1.0000
3950/6454 [=================>............] - ETA: 10:11 - loss: 1.1925e-07 - acc: 1.0000
4000/6454 [=================>............] - ETA: 9:59 - loss: 1.1925e-07 - acc: 1.0000 
4050/6454 [=================>............] - ETA: 9:47 - loss: 1.1925e-07 - acc: 1.0000
4100/6454 [==================>...........] - ETA: 9:35 - loss: 1.1925e-07 - acc: 1.0000
4150/6454 [==================>...........] - ETA: 9:23 - loss: 1.1925e-07 - acc: 1.0000
4200/6454 [==================>...........] - ETA: 9:11 - loss: 1.1925e-07 - acc: 1.0000
4250/6454 [==================>...........] - ETA: 8:59 - loss: 1.1925e-07 - acc: 1.0000
4300/6454 [==================>...........] - ETA: 8:52 - loss: 1.1925e-07 - acc: 1.0000
4350/6454 [===================>..........] - ETA: 8:40 - loss: 1.1925e-07 - acc: 1.0000
4400/6454 [===================>..........] - ETA: 8:29 - loss: 1.1933e-07 - acc: 1.0000
4450/6454 [===================>..........] - ETA: 8:16 - loss: 1.1933e-07 - acc: 1.0000
4500/6454 [===================>..........] - ETA: 8:04 - loss: 1.1933e-07 - acc: 1.0000
4550/6454 [====================>.........] - ETA: 7:52 - loss: 1.1933e-07 - acc: 1.0000
4600/6454 [====================>.........] - ETA: 7:41 - loss: 1.1933e-07 - acc: 1.0000
4650/6454 [====================>.........] - ETA: 7:28 - loss: 1.1932e-07 - acc: 1.0000
4700/6454 [====================>.........] - ETA: 7:15 - loss: 1.1932e-07 - acc: 1.0000
4750/6454 [=====================>........] - ETA: 7:02 - loss: 1.1932e-07 - acc: 1.0000
4800/6454 [=====================>........] - ETA: 6:50 - loss: 1.1932e-07 - acc: 1.0000
4850/6454 [=====================>........] - ETA: 6:37 - loss: 1.1932e-07 - acc: 1.0000
4900/6454 [=====================>........] - ETA: 6:25 - loss: 1.1932e-07 - acc: 1.0000
4950/6454 [======================>.......] - ETA: 6:13 - loss: 1.1932e-07 - acc: 1.0000
5000/6454 [======================>.......] - ETA: 6:00 - loss: 1.1932e-07 - acc: 1.0000
5050/6454 [======================>.......] - ETA: 5:48 - loss: 1.1932e-07 - acc: 1.0000
5100/6454 [======================>.......] - ETA: 5:35 - loss: 1.1931e-07 - acc: 1.0000
5150/6454 [======================>.......] - ETA: 5:23 - loss: 1.1931e-07 - acc: 1.0000
5200/6454 [=======================>......] - ETA: 5:10 - loss: 1.1931e-07 - acc: 1.0000
5250/6454 [=======================>......] - ETA: 4:57 - loss: 1.1931e-07 - acc: 1.0000
5300/6454 [=======================>......] - ETA: 4:45 - loss: 1.1931e-07 - acc: 1.0000
5350/6454 [=======================>......] - ETA: 4:33 - loss: 1.1931e-07 - acc: 1.0000
5400/6454 [========================>.....] - ETA: 2:32:06 - loss: 1.1931e-07 - acc: 1.0000
5450/6454 [========================>.....] - ETA: 2:23:35 - loss: 1.1931e-07 - acc: 1.0000
5500/6454 [========================>.....] - ETA: 2:15:12 - loss: 1.1931e-07 - acc: 1.0000
5550/6454 [========================>.....] - ETA: 2:06:59 - loss: 1.1931e-07 - acc: 1.0000
5600/6454 [=========================>....] - ETA: 1:58:54 - loss: 1.1931e-07 - acc: 1.0000
5650/6454 [=========================>....] - ETA: 1:50:58 - loss: 1.1930e-07 - acc: 1.0000
5700/6454 [=========================>....] - ETA: 1:43:10 - loss: 1.1930e-07 - acc: 1.0000
5750/6454 [=========================>....] - ETA: 1:35:30 - loss: 1.1930e-07 - acc: 1.0000
5800/6454 [=========================>....] - ETA: 1:27:57 - loss: 1.1930e-07 - acc: 1.0000
5850/6454 [==========================>...] - ETA: 1:20:33 - loss: 1.1930e-07 - acc: 1.0000
5900/6454 [==========================>...] - ETA: 1:13:16 - loss: 1.1930e-07 - acc: 1.0000
5950/6454 [==========================>...] - ETA: 1:06:06 - loss: 1.1930e-07 - acc: 1.0000
6000/6454 [==========================>...] - ETA: 59:03 - loss: 1.1930e-07 - acc: 1.0000  
6050/6454 [===========================>..] - ETA: 52:07 - loss: 1.1930e-07 - acc: 1.0000
6100/6454 [===========================>..] - ETA: 45:18 - loss: 1.1930e-07 - acc: 1.0000
6150/6454 [===========================>..] - ETA: 38:35 - loss: 1.1930e-07 - acc: 1.0000
6200/6454 [===========================>..] - ETA: 31:59 - loss: 1.1930e-07 - acc: 1.0000
6250/6454 [============================>.] - ETA: 25:29 - loss: 1.1930e-07 - acc: 1.0000
6300/6454 [============================>.] - ETA: 19:05 - loss: 1.1929e-07 - acc: 1.0000
6350/6454 [============================>.] - ETA: 12:47 - loss: 1.1929e-07 - acc: 1.0000
6400/6454 [============================>.] - ETA: 6:35 - loss: 1.1929e-07 - acc: 1.0000 
6450/6454 [============================>.] - ETA: 29s - loss: 1.1929e-07 - acc: 1.0000 
6454/6454 [==============================] - 46889s 7s/step - loss: 1.1929e-07 - acc: 1.0000 - val_loss: 1.1921e-07 - val_acc: 1.0000

最后输出预测test.csv的label：

[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]
 ```
